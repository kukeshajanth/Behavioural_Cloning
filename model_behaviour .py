# -*- coding: utf-8 -*-
"""model_behaviour.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QFmTk9Iu2hY9e-M37Y2mxqQX-nSJS1bx
"""

from urllib.request import urlretrieve
import os
import numpy as np
from sklearn.preprocessing import LabelBinarizer
from zipfile import ZipFile

def download(url, file):
    
    urlretrieve(url, file)
    print('retireved')
    
download('https://behaviourcloning1.s3.us-east-2.amazonaws.com/data.zip','data.zip')

def uncompress(dir):
  
  with ZipFile(dir) as zipf:
    zipf.extractall('data')
    print('extracted')
    
uncompress('data.zip')

os.listdir('data/data')

import csv
import pandas as pd

os.chdir('data')
df = pd.read_csv('./data/out.csv')
df.head()

sets = df.values.tolist()

print(sets[:5])

print(df[:5])

from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split

train_set, validation_set = train_test_split(sets , test_size = 0.2)

import cv2
import numpy as np
import sklearn
import matplotlib.pyplot as plt
from skimage import exposure, img_as_ubyte
from skimage.util import random_noise

def generator(sets, batch = 64):
  
  len_sets = len(sets)
  
  while 1:
    shuffle(sets)
    
    for offset in range(0, len_sets , batch):
      
      batch_sets = sets[offset:offset+batch]
      
      images = []
      angles = []
      
      for line in batch_sets: 
        
        for i in range(0,3): #to get centre, left and right images
          
          name = './data/IMG/' + line[i].split('/')[-1]
          
          centre_image = cv2.cvtColor(cv2.imread(name), cv2.COLOR_BGR2RGB)
          
          centre_angle = float(line[3])
          
          images.append(centre_image)
          
          if(i == 0):
            angles.append(centre_angle)
          elif(i == 1):
            angles.append(centre_angle + 0.2)
          elif (i== 2):
            angles.append(centre_angle - 0.2)
            
          images.append(cv2.flip(centre_image,1))
          
          if(i==0):
            angles.append(centre_angle * -1)
          elif(i == 1):
            angles.append((centre_angle + 0.2) * -1)
          elif(i == 2):
            angles.append((centre_angle - 0.2) * -1)
            
          
          aug_img = cv2.cvtColor(centre_image,cv2.COLOR_RGB2HSV)  #randomising brighness value
          brightness = .25 + np.random.uniform()
          aug_img[::2] =  aug_img[::2] * brightness
          aug_img = cv2.cvtColor(aug_img, cv2.COLOR_HSV2RGB)
          
          images.append(aug_img)
          
          if(i == 0):
            angles.append(centre_angle)
          elif(i == 1):
            angles.append(centre_angle + 0.2)
          elif (i== 2):
            angles.append(centre_angle - 0.2)
          
          aug_img_eq = np.copy(centre_image)
          for channel in range(aug_img_eq.shape[2]):
            aug_img_eq[:,:, channel] = exposure.equalize_hist(aug_img_eq[:,:, channel])* 255
            
          images.append(aug_img_eq)
          
          if(i==0):
            angles.append(centre_angle * -1)
          elif(i == 1):
            angles.append((centre_angle + 0.2) * -1)
          elif(i == 2):
            angles.append((centre_angle - 0.2) * -1)
          
          
          aug_img_noise = img_as_ubyte(random_noise(centre_image, mode = 'gaussian'))
          
          images.append(aug_img_noise)
          
          if(i==0):
            angles.append(centre_angle * -1)
          elif(i == 1):
            angles.append((centre_angle + 0.2) * -1)
          elif(i == 2):
            angles.append((centre_angle - 0.2) * -1)    
          
           
      X_train = np.array(images)
      y_train = np.array(angles)
      
      yield sklearn.utils.shuffle(X_train,y_train)
      
      
train_generator = generator(train_set, batch = 8)
validation_generator = generator(validation_set, batch = 8)

from keras.models import Sequential
from keras.layers.core import Dense, Flatten, Activation, Dropout
from keras.layers.convolutional import Convolution2D
from keras.layers import Lambda, Cropping2D

model = Sequential()

#normalizing the images and mean centering
model.add(Lambda(lambda x: (x/ 255.0) - 0.5 ,input_shape = (160,320,3)))
#cropping the images while passing into the model(selecting required part of image)
model.add(Cropping2D(cropping = ((70,25),(0,0))))

model.add(Convolution2D(24,5,5,subsample = (2,2)))
model.add(Activation('elu'))

model.add(Convolution2D(36,5,5,subsample = (2,2)))
model.add(Activation('elu'))

model.add(Convolution2D(48,5,5,subsample = (2,2)))
model.add(Activation('elu'))

model.add(Convolution2D(64,3,3))
model.add(Activation('elu'))

model.add(Convolution2D(64,3,3))
model.add(Activation('elu'))

model.add(Flatten())

model.add(Dense(100))
model.add(Activation('elu'))

model.add(Dropout(0.25))

model.add(Dense(50))
model.add(Activation('elu'))

model.add(Dense(10))
model.add(Activation('elu'))

model.add(Dense(1))

model.compile(loss = 'mse', optimizer = 'adam')

model.fit_generator(train_generator,samples_per_epoch = len(train_set),validation_data = validation_generator, nb_val_samples = len(validation_set),nb_epoch = 5, verbose = 1)

model.summary()
model.save('model.h5')

print('Model Saved!')

import matplotlib.pyplot as plt



f, ax = plt.subplots(3, 5, figsize=(16, 4))

for idx, img in enumerate(images[:14]):
  ax[idx//5, idx%5].imshow(img)

